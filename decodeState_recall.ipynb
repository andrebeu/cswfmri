{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import brainiak\n",
    "import nilearn as nl\n",
    "from nilearn import image, plotting, input_data\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes with timing and order information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_df = pd.read_csv('deriv/view_df.csv',index_col=0)\n",
    "view_df.iloc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_df = pd.read_csv('deriv/recall_df.csv',index_col=0)\n",
    "# recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# form training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_num,layer_num = 33,3\n",
    "def get_training_info(sub_num,layer_num):\n",
    "  # find df rows corresponding to sub/layer\n",
    "  layer_bool = view_df.state.str[0]==str(layer_num)\n",
    "  sub_layer_view_df = view_df[(view_df.sub_num == sub_num) & layer_bool]\n",
    "  # extract TRs and labels \n",
    "  TR_L = []\n",
    "  ytarget_L = []\n",
    "  for idx,row in sub_layer_view_df.iterrows():\n",
    "    TRs = np.arange(row.onset_TR,row.offset_TR)\n",
    "    TR_L.extend(TRs)\n",
    "    ytarget_L.extend(np.repeat(row.state[1]=='a',len(TRs)))\n",
    "  return np.array(TR_L),np.array(ytarget_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "build testing dataset\n",
    "\"\"\" \n",
    "\n",
    "## dict mapping (layer,state):recall_transcript_code\n",
    "recall_label_D = {\n",
    "  (2,'a'):3,\n",
    "  (2,'b'):4,\n",
    "  (3,'a'):5,\n",
    "  (3,'b'):6,\n",
    "  (4,'a'):7,\n",
    "  (4,'b'):8\n",
    "}\n",
    "\n",
    "def get_test_info(sub_num,layer_num):\n",
    "  \"\"\" \n",
    "  build testing dataset\n",
    "  find TRs during recall when sub is recalling given state+layer\n",
    "  along with labels for these recall TRs when recalling layer\n",
    "  \"\"\"\n",
    "  ytarget = []\n",
    "  XTRs = []\n",
    "  sub_recall_df = recall_df[recall_df.sub_num==sub_num]\n",
    "  for state_id in ['a','b']:\n",
    "    # from layer+state get transcript_code\n",
    "    recall_code = recall_label_D[(layer_num,state_id)]\n",
    "    # find TRs where sub talks about layer+state\n",
    "    TRs_state = sub_recall_df[sub_recall_df.recall==recall_code].index.values\n",
    "    XTRs.extend(TRs_state)\n",
    "    ytarget.extend(np.repeat(state_id,len(TRs_state)))\n",
    "  return XTRs,np.array(ytarget)=='a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_roi(sub_num,roi_name,task):\n",
    "  fpath = \"sub-%i_task-%s_roi-%s.npy\" %(sub_num,task,roi_name)\n",
    "  return np.load('data/fmri/masked/'+fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_NAME_L = [\n",
    "  'SnPM_filtered_FDR',\n",
    "  'rglasser_AT_net',\n",
    "  'rglasser_MP_net',\n",
    "  'rglasser_MTN_net',\n",
    "  'rglasser_PM_net',\n",
    "  'rhippocampusAAL', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_name= 'rglasser_PM_net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_NAME_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "train and test classifier\n",
    "\"\"\"\n",
    "\n",
    "L = []\n",
    "for roi_name,sub_num,layer_num in itertools.product(ROI_NAME_L,np.arange(45),range(2,5)):\n",
    "  print('r',roi_name,'sub',sub_num,'layer',layer_num)\n",
    "  # load fmri data; \n",
    "  try: # check that fmri files exist\n",
    "    sub_roi_view = load_sub_roi(sub_num,roi_name,'videos')\n",
    "    sub_roi_recall = load_sub_roi(sub_num,roi_name,'recall2')\n",
    "    assert len(sub_roi_view)\n",
    "    assert len(sub_roi_recall)\n",
    "  except:\n",
    "    print('err loading roi data')\n",
    "    continue\n",
    "  ## build train/test datasets\n",
    "  try:\n",
    "    train_TRs,Ytrain = get_training_info(sub_num,layer_num)\n",
    "    test_TRs,Ytest = get_test_info(sub_num,layer_num)\n",
    "    Xtrain = sub_roi_view[train_TRs,:] \n",
    "    Xtest = sub_roi_recall[test_TRs,:]\n",
    "  except:\n",
    "    print('err finding info to build classifier dataset')\n",
    "    continue\n",
    "  # check if recall data exists\n",
    "  if not len(Xtest): \n",
    "    print('no recall data. sub',sub_num,'layer',layer_num)\n",
    "    continue\n",
    "  ## normalize\n",
    "  scaler = StandardScaler()\n",
    "  Xtrain = scaler.fit_transform(Xtrain)\n",
    "  Xtest = scaler.transform(Xtest)\n",
    "  ## fit classifier\n",
    "  clf = sklearn.linear_model.LogisticRegression(solver='liblinear',C=1.00)\n",
    "  clf.fit(Xtrain,Ytrain)\n",
    "  # eval classifier\n",
    "  yhat = clf.predict_proba(Xtrain)\n",
    "  score = clf.score(Xtest,Ytest)\n",
    "  # record data\n",
    "  D = {}\n",
    "  D['sub_num']=sub_num\n",
    "  D['roi']=roi_name\n",
    "  D['layer']=layer_num\n",
    "  D['num_test_samples']=len(Ytest)\n",
    "  D['score']=score  \n",
    "  L.append(D)\n",
    "\n",
    "## \n",
    "results = pd.DataFrame(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsubs = len(results.sub_num.unique())\n",
    "results.to_csv('data/analyses/decodeState_trainView_testRecall-N%i.csv'%Nsubs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
