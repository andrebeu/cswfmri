{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import brainiak\n",
    "import nilearn as nl\n",
    "from nilearn import image, plotting, input_data\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes with timing and order information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_num</th>\n",
       "      <th>wed_id</th>\n",
       "      <th>onset_recall2</th>\n",
       "      <th>offset_recall2</th>\n",
       "      <th>wed_class</th>\n",
       "      <th>wed_view_num</th>\n",
       "      <th>onset_videos</th>\n",
       "      <th>offset_videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>201</td>\n",
       "      <td>236</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>879</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>236</td>\n",
       "      <td>263</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>687</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>263</td>\n",
       "      <td>277</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>591</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>277</td>\n",
       "      <td>307</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>307</td>\n",
       "      <td>-1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>976</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>687</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>124</td>\n",
       "      <td>164</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>783</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_num  wed_id  onset_recall2  offset_recall2 wed_class  wed_view_num  \\\n",
       "55        6      28            201             236         N             9   \n",
       "56        6      29            236             263         S             7   \n",
       "57        6       2            263             277         N             6   \n",
       "58        6       6            277             307         S             0   \n",
       "59        6      20            307              -1         N             2   \n",
       "60        7       1              0              26         N             1   \n",
       "61        7      34             26              71         N            10   \n",
       "62        7      38             71              88         S             7   \n",
       "63        7      23             88             124         S             0   \n",
       "64        7      29            124             164         S             8   \n",
       "\n",
       "    onset_videos  offset_videos  \n",
       "55           879            952  \n",
       "56           687            759  \n",
       "57           591            663  \n",
       "58            12             90  \n",
       "59           207            279  \n",
       "60           111            183  \n",
       "61           976           1048  \n",
       "62           687            759  \n",
       "63            12             90  \n",
       "64           783            856  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed_df = pd.read_csv('deriv/wed_df.csv',index_col=0)\n",
    "wed_df.iloc[55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_roi(sub_num,roi_name,task):\n",
    "  fpath = \"sub-%i_task-%s_roi-%s.npy\" %(sub_num,task,roi_name)\n",
    "  return np.load('data/fmri/masked/'+fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(sub_num,roi_name,task):\n",
    "  \"\"\"\n",
    "  task: [videos,recall2]\n",
    "  returns the func data for given sub/roi/task for all 12 weddings\n",
    "  \"\"\"\n",
    "  try:\n",
    "    sub_roi_act = load_sub_roi(sub_num,roi_name,task)\n",
    "    sub_wed_df = wed_df[wed_df.sub_num==sub_num]\n",
    "  except:\n",
    "    print('err loading sub',sub_num)\n",
    "  Xact_L,ytarget_L = [],[]\n",
    "  stimstr_L = []\n",
    "  for idx,df_row in sub_wed_df.iterrows():\n",
    "    Xact_wed = sub_roi_act[df_row.loc['onset_%s'%task]:df_row.loc['offset_%s'%task]]\n",
    "    ytarget_wed = np.repeat(int(df_row.wed_class == 'N'),len(Xact_wed))\n",
    "    Xact_L.append(Xact_wed)\n",
    "    ytarget_L.append(ytarget_wed)\n",
    "    # string identifying test sequences\n",
    "    stimstr = \"wed_%i-class_%s\"%(df_row.wed_id,df_row.wed_class)\n",
    "    stimstr_L.append(stimstr)\n",
    "  return Xact_L,ytarget_L,stimstr_L\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_num,roi_name,task = 32,'rglasser_PM_net','recall2'\n",
    "clf_c = 1.00\n",
    "## train data\n",
    "Xact_train_L,ytarget_train_L,stimstr_L = get_data(sub_num,roi_name,'videos')\n",
    "ytarget_train = np.concatenate(ytarget_train_L)\n",
    "Xact_train = np.concatenate(Xact_train_L)\n",
    "## test data\n",
    "Xact_test_L,ytarget_test_L = get_data(sub_num,roi_name,'recall2')\n",
    "\n",
    "# NORMALIZE\n",
    "scaler = StandardScaler()\n",
    "Xact_train = scaler.fit_transform(Xact_train)\n",
    "Xact_test_L = [scaler.transform(Xact) for Xact in Xact_test_L]\n",
    "\n",
    "# # CLASSIFIER\n",
    "clf = sklearn.linear_model.LogisticRegression(solver='liblinear',C=clf_c)\n",
    "clf.fit(Xact_train,ytarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634830652480973\n",
      "0.48693049570784674\n",
      "0.33216295137340035\n",
      "0.4256327861090206\n",
      "0.4310072150460813\n",
      "0.28850854664181297\n",
      "0.42979298462339904\n",
      "0.5259397546461783\n",
      "0.4240178337153569\n",
      "0.37273443166362136\n",
      "0.5843174402876236\n",
      "0.6017817485216655\n"
     ]
    }
   ],
   "source": [
    "## EVAL LOOP: loop over 12 weddings for eval\n",
    "for idx_test in range(12):\n",
    "  # eval data for given wedding\n",
    "  Xact_test_wed = Xact_test_L[idx_test]\n",
    "  ytarget_test_wed = np.unique(ytarget_test_L[idx_test])\n",
    "  # fit classifier\n",
    "  yhat_wed = clf.predict_proba(Xact_test_wed)[:,ytarget_test_wed]\n",
    "  print(yhat_wed.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_NS = np.arange(1,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "xval loop \n",
    "\"\"\"\n",
    "\n",
    "def xval(roi_name,clf_c):\n",
    "  yhat_L = []\n",
    "  for sub_num in SUB_NS:\n",
    "    print(sub_num)\n",
    "    try:\n",
    "      sub_roi = load_sub_roi(sub_num,'videos',roi_name)\n",
    "    except:\n",
    "      print('failed to load sub_roi, S=',sub_num,'roi=',roi_name)\n",
    "      continue\n",
    "    # fold information\n",
    "    for fold_num in range(6):\n",
    "      fold_L_test = fold_full_L[fold_num]\n",
    "      fold_L_train = get_fold_L_train(fold_num)\n",
    "      print('test',fold_L_test,'train',fold_L_train)\n",
    "      # TRAIN DATA\n",
    "      X_TRs_train,Y_train = get_fold_info(sub_num,fold_L_train)\n",
    "      X_train = sub_roi[X_TRs_train,:]\n",
    "      # TEST DATA\n",
    "      X_TRs_test,Y_test = get_fold_info(sub_num,fold_L_test)\n",
    "      X_test = sub_roi[X_TRs_test,:]\n",
    "      # NORMALIZE\n",
    "      scaler = StandardScaler()\n",
    "      X_train = scaler.fit_transform(X_train)\n",
    "      X_test = scaler.transform(X_test)\n",
    "      # CLASSIFIER\n",
    "      clf = sklearn.linear_model.LogisticRegression(solver='liblinear',C=clf_c)\n",
    "      clf.fit(X_train,Y_train)\n",
    "      yhat_full = clf.predict_proba(X_test)\n",
    "      # split eval of test TRs into two weddings\n",
    "      # and plot proba of correct schema\n",
    "      yhat_first = yhat_full[:int(len(yhat_full)/2),Y_test[0]]\n",
    "      yhat_second = yhat_full[int(len(yhat_full)/2):,Y_test[-1]]\n",
    "      yhat_L.append(yhat_first)\n",
    "      yhat_L.append(yhat_second)\n",
    "  return np.array(yhat_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## compute mean\n",
    "roi_name = 'rglasser_PM_net'\n",
    "clf_c = 1.0\n",
    "yhat = xval(roi_name=roi_name,clf_c=clf_c)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = yhat.mean(0)\n",
    "S = yhat.std(0) / np.sqrt(len(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plt\n",
    "ax = plt.gca()\n",
    "ax.plot(M)\n",
    "ax.fill_between(np.arange(len(M)),M-S,M+S,alpha=.3)\n",
    "ax.axhline(0.5,c='k',ls='--')\n",
    "ax.set_ylim(0.2,0.8)\n",
    "ax.set_title('roi-%s_C_%.4f'%(roi_name,clf_c))\n",
    "plt.savefig('figures/NvS_logreg_roi-%s_C%.4f-nsubs_%i.png'%(roi_name,clf_c,int(len(M)/12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
