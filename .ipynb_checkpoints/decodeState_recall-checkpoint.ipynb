{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import brainiak\n",
    "import nilearn as nl\n",
    "from nilearn import image, plotting, input_data\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall legend\n",
    "- 3,4: layer 2\n",
    "- 5,6: layer 3\n",
    "- 7,8: layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_df = pd.read_csv('deriv/view_df.csv',index_col=0)\n",
    "# view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wed_df = pd.read_csv('deriv/wed_df.csv',index_col=0)\n",
    "wed_df.path = wed_df.path.fillna('NA')\n",
    "# wed_df.iloc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_df = pd.read_csv('deriv/recall_df.csv',index_col=0)\n",
    "# recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes with timing and order information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_roi(sub_num,roi_name,task):\n",
    "  fpath = \"sub-%i_task-%s_roi-%s.npy\" %(sub_num,task,roi_name)\n",
    "  return np.load('data/fmri/masked/'+fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view-recall state classifier\n",
    "- different decoder for each sub/layer\n",
    "-- each sub has 3 decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "build training dataset\n",
    "\"\"\"\n",
    "\n",
    "pathlayer2label_D = {\n",
    "  ('NA',2):'a',\n",
    "  ('NA',3):'a',\n",
    "  ('NA',4):'a',\n",
    "  ('NB',2):'b',\n",
    "  ('NB',3):'b',\n",
    "  ('NB',4):'b',\n",
    "  ('SA',2):'a',\n",
    "  ('SA',3):'b',\n",
    "  ('SA',4):'a',\n",
    "  ('SB',2):'b',\n",
    "  ('SB',3):'a',\n",
    "  ('SB',4):'b',\n",
    "}\n",
    "\n",
    "def get_training_info(sub_num,layer_num):\n",
    "  \"\"\"\n",
    "  for given subject/layer \n",
    "  returns info needed to train state classifier\n",
    "    the TRs when viewing layer (for all 12 weddings)\n",
    "    and the labels of the states for that layer\n",
    "  \"\"\"\n",
    "  ytarget_L = []\n",
    "  TR_L = []\n",
    "  # wed_df contains labels for given wedding \n",
    "  # select subject specific rows of wed_df\n",
    "  sub_wed_df = wed_df[wed_df.sub_num==sub_num]\n",
    "  for wed_num in range(12):\n",
    "    path = sub_wed_df[sub_wed_df.wed_view_num==wed_num].path.values[0]\n",
    "    wed_bool = (view_df.wed_num == wed_num) \n",
    "    layer_bool = (view_df.vid_str.str[:len('vid1')] == 'vid%i'%layer_num)\n",
    "    # TRs for given state (for given sub/layer)\n",
    "    onsetTR,offsetTR = view_df[wed_bool&layer_bool].loc[:,('onset_TR','offset_TR')].values[0]\n",
    "    state_TRs = np.arange(onsetTR,offsetTR)\n",
    "    # state label\n",
    "    state_label = pathlayer2label_D[(path,layer_num)]\n",
    "    # \n",
    "    TR_L.extend(state_TRs)\n",
    "    ytarget_L.extend(np.repeat(state_label=='a',len(state_TRs)))\n",
    "  return np.array(TR_L),np.array(ytarget_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "build testing dataset\n",
    "\"\"\" \n",
    "\n",
    "## dict mapping (layer,state):recall_transcript_code\n",
    "recall_label_D = {\n",
    "  (2,'a'):3,\n",
    "  (2,'b'):4,\n",
    "  (3,'a'):5,\n",
    "  (3,'b'):6,\n",
    "  (4,'a'):7,\n",
    "  (4,'b'):8\n",
    "}\n",
    "\n",
    "def get_test_info(sub_num,layer_num):\n",
    "  \"\"\" \n",
    "  build testing dataset\n",
    "  find TRs during recall when sub is recalling given state+layer\n",
    "  along with labels for these recall TRs when recalling layer\n",
    "  \"\"\"\n",
    "  ytarget = []\n",
    "  XTRs = []\n",
    "  sub_recall_df = recall_df[recall_df.sub_num==sub_num]\n",
    "  for state_id in ['a','b']:\n",
    "    # from layer+state get transcript_code\n",
    "    recall_code = recall_label_D[(layer_num,state_id)]\n",
    "    # find TRs where sub talks about layer+state\n",
    "    TRs_state = sub_recall_df[sub_recall_df.recall==recall_code].index.values\n",
    "    XTRs.extend(TRs_state)\n",
    "    ytarget.extend(np.repeat(state_id,len(TRs_state)))\n",
    "  return XTRs,np.array(ytarget)=='a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 0 l 2\n",
      "err loading sub 0\n",
      "s 0 l 3\n",
      "err loading sub 0\n",
      "s 0 l 4\n",
      "err loading sub 0\n",
      "s 1 l 2\n",
      "err loading sub 1\n",
      "s 1 l 3\n",
      "err loading sub 1\n",
      "s 1 l 4\n",
      "err loading sub 1\n",
      "s 2 l 2\n",
      "err loading sub 2\n",
      "s 2 l 3\n",
      "err loading sub 2\n",
      "s 2 l 4\n",
      "err loading sub 2\n",
      "s 3 l 2\n",
      "err loading sub 3\n",
      "s 3 l 3\n",
      "err loading sub 3\n",
      "s 3 l 4\n",
      "err loading sub 3\n",
      "s 4 l 2\n",
      "err loading sub 4\n",
      "s 4 l 3\n",
      "err loading sub 4\n",
      "s 4 l 4\n",
      "err loading sub 4\n",
      "s 5 l 2\n",
      "err loading sub 5\n",
      "s 5 l 3\n",
      "err loading sub 5\n",
      "s 5 l 4\n",
      "err loading sub 5\n",
      "s 6 l 2\n",
      "err loading sub 6\n",
      "s 6 l 3\n",
      "err loading sub 6\n",
      "s 6 l 4\n",
      "err loading sub 6\n",
      "s 7 l 2\n",
      "err loading sub 7\n",
      "s 7 l 3\n",
      "err loading sub 7\n",
      "s 7 l 4\n",
      "err loading sub 7\n",
      "s 8 l 2\n",
      "err loading sub 8\n",
      "s 8 l 3\n",
      "err loading sub 8\n",
      "s 8 l 4\n",
      "err loading sub 8\n",
      "s 9 l 2\n",
      "err loading sub 9\n",
      "s 9 l 3\n",
      "err loading sub 9\n",
      "s 9 l 4\n",
      "err loading sub 9\n",
      "s 10 l 2\n",
      "err loading sub 10\n",
      "s 10 l 3\n",
      "err loading sub 10\n",
      "s 10 l 4\n",
      "err loading sub 10\n",
      "s 11 l 2\n",
      "err loading sub 11\n",
      "s 11 l 3\n",
      "err loading sub 11\n",
      "s 11 l 4\n",
      "err loading sub 11\n",
      "s 12 l 2\n",
      "err loading sub 12\n",
      "s 12 l 3\n",
      "err loading sub 12\n",
      "s 12 l 4\n",
      "err loading sub 12\n",
      "s 13 l 2\n",
      "err loading sub 13\n",
      "s 13 l 3\n",
      "err loading sub 13\n",
      "s 13 l 4\n",
      "err loading sub 13\n",
      "s 14 l 2\n",
      "err loading sub 14\n",
      "s 14 l 3\n",
      "err loading sub 14\n",
      "s 14 l 4\n",
      "err loading sub 14\n",
      "s 15 l 2\n",
      "err loading sub 15\n",
      "s 15 l 3\n",
      "err loading sub 15\n",
      "s 15 l 4\n",
      "err loading sub 15\n",
      "s 16 l 2\n",
      "err loading sub 16\n",
      "s 16 l 3\n",
      "err loading sub 16\n",
      "s 16 l 4\n",
      "err loading sub 16\n",
      "s 17 l 2\n",
      "err loading sub 17\n",
      "s 17 l 3\n",
      "err loading sub 17\n",
      "s 17 l 4\n",
      "err loading sub 17\n",
      "s 18 l 2\n",
      "err loading sub 18\n",
      "s 18 l 3\n",
      "err loading sub 18\n",
      "s 18 l 4\n",
      "err loading sub 18\n",
      "s 19 l 2\n",
      "err loading sub 19\n",
      "s 19 l 3\n",
      "err loading sub 19\n",
      "s 19 l 4\n",
      "err loading sub 19\n",
      "s 20 l 2\n",
      "err loading sub 20\n",
      "s 20 l 3\n",
      "err loading sub 20\n",
      "s 20 l 4\n",
      "err loading sub 20\n",
      "s 21 l 2\n",
      "err loading sub 21\n",
      "s 21 l 3\n",
      "err loading sub 21\n",
      "s 21 l 4\n",
      "err loading sub 21\n",
      "s 22 l 2\n",
      "err loading sub 22\n",
      "s 22 l 3\n",
      "err loading sub 22\n",
      "s 22 l 4\n",
      "err loading sub 22\n",
      "s 23 l 2\n",
      "err loading sub 23\n",
      "s 23 l 3\n",
      "err loading sub 23\n",
      "s 23 l 4\n",
      "err loading sub 23\n",
      "s 24 l 2\n",
      "err loading sub 24\n",
      "s 24 l 3\n",
      "err loading sub 24\n",
      "s 24 l 4\n",
      "err loading sub 24\n",
      "s 25 l 2\n",
      "err loading sub 25\n",
      "s 25 l 3\n",
      "err loading sub 25\n",
      "s 25 l 4\n",
      "err loading sub 25\n",
      "s 26 l 2\n",
      "err loading sub 26\n",
      "s 26 l 3\n",
      "err loading sub 26\n",
      "s 26 l 4\n",
      "err loading sub 26\n",
      "s 27 l 2\n",
      "err loading sub 27\n",
      "s 27 l 3\n",
      "err loading sub 27\n",
      "s 27 l 4\n",
      "err loading sub 27\n",
      "s 28 l 2\n",
      "err loading sub 28\n",
      "s 28 l 3\n",
      "err loading sub 28\n",
      "s 28 l 4\n",
      "err loading sub 28\n",
      "s 29 l 2\n",
      "err loading sub 29\n",
      "s 29 l 3\n",
      "err loading sub 29\n",
      "s 29 l 4\n",
      "err loading sub 29\n",
      "s 30 l 2\n",
      "s 30 l 3\n",
      "s 30 l 4\n",
      "s 31 l 2\n",
      "s 31 l 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/brain/lib/python3.6/site-packages/ipykernel_launcher.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no recall data. sub 31 layer 3\n",
      "s 31 l 4\n",
      "s 32 l 2\n",
      "s 32 l 3\n",
      "s 32 l 4\n",
      "s 33 l 2\n",
      "s 33 l 3\n",
      "s 33 l 4\n",
      "s 34 l 2\n",
      "s 34 l 3\n",
      "s 34 l 4\n",
      "s 35 l 2\n",
      "s 35 l 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/brain/lib/python3.6/site-packages/ipykernel_launcher.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no recall data. sub 35 layer 3\n",
      "s 35 l 4\n",
      "s 36 l 2\n",
      "s 36 l 3\n",
      "s 36 l 4\n",
      "s 37 l 2\n",
      "err loading sub 37\n",
      "s 37 l 3\n",
      "err loading sub 37\n",
      "s 37 l 4\n",
      "err loading sub 37\n",
      "s 38 l 2\n",
      "s 38 l 3\n",
      "no recall data. sub 38 layer 3\n",
      "s 38 l 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/brain/lib/python3.6/site-packages/ipykernel_launcher.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 39 l 2\n",
      "err loading sub 39\n",
      "s 39 l 3\n",
      "err loading sub 39\n",
      "s 39 l 4\n",
      "err loading sub 39\n",
      "s 40 l 2\n",
      "err loading sub 40\n",
      "s 40 l 3\n",
      "err loading sub 40\n",
      "s 40 l 4\n",
      "err loading sub 40\n",
      "s 41 l 2\n",
      "err loading sub 41\n",
      "s 41 l 3\n",
      "err loading sub 41\n",
      "s 41 l 4\n",
      "err loading sub 41\n",
      "s 42 l 2\n",
      "err loading sub 42\n",
      "s 42 l 3\n",
      "err loading sub 42\n",
      "s 42 l 4\n",
      "err loading sub 42\n",
      "s 43 l 2\n",
      "err loading sub 43\n",
      "s 43 l 3\n",
      "err loading sub 43\n",
      "s 43 l 4\n",
      "err loading sub 43\n",
      "s 44 l 2\n",
      "err loading sub 44\n",
      "s 44 l 3\n",
      "err loading sub 44\n",
      "s 44 l 4\n",
      "err loading sub 44\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "train and test classifier\n",
    "\"\"\"\n",
    "\n",
    "roi_name= 'rglasser_PM_net'\n",
    "clf_c = 1.00\n",
    "\n",
    "L = []\n",
    "for sub_num,layer_num in itertools.product(np.arange(45),range(2,5)):\n",
    "  print('s',sub_num,'l',layer_num)\n",
    "  # load fmri data; \n",
    "  try: # check that fmri files exist\n",
    "    sub_roi_view = load_sub_roi(sub_num,roi_name,'videos')\n",
    "    sub_roi_recall = load_sub_roi(sub_num,roi_name,'recall2')\n",
    "    assert len(sub_roi_view)\n",
    "    assert len(sub_roi_recall)\n",
    "  except:\n",
    "    print('err loading sub',sub_num)\n",
    "    continue\n",
    "  ## build train/test datasets\n",
    "  # train\n",
    "  train_TRs,Ytrain = get_training_info(sub_num,layer_num)\n",
    "  Xtrain = sub_roi_view[train_TRs,:]\n",
    "  # test  \n",
    "  test_TRs,Ytest = get_test_info(sub_num,layer_num)\n",
    "  Xtest = sub_roi_recall[test_TRs,:]\n",
    "  # check if recall data exists\n",
    "  if not len(Xtest): \n",
    "    print('no recall data. sub',sub_num,'layer',layer_num)\n",
    "    continue\n",
    "  ## normalize\n",
    "  scaler = StandardScaler()\n",
    "  Xtrain = scaler.fit_transform(Xtrain)\n",
    "  Xtest = scaler.transform(Xtest)\n",
    "  ## fit classifier\n",
    "  clf = sklearn.linear_model.LogisticRegression(solver='liblinear',C=clf_c)\n",
    "  clf.fit(Xtrain,Ytrain)\n",
    "  # eval classifier\n",
    "  yhat = clf.predict_proba(Xtrain)\n",
    "  score = clf.score(Xtest,Ytest)\n",
    "  # record\n",
    "  D = {}\n",
    "  D['num_test_samples']=len(Ytest)\n",
    "  D['sub_num']=sub_num\n",
    "  D['layer']=layer_num\n",
    "  D['score']=score\n",
    "  L.append(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(L)\n",
    "results.to_csv('data/analyses/decodeState_trainView_testRecall.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
