{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the goal of this NB is to create the file `state_df_viewing.csv` which contains information about what event/ceremony was visited on what TR\n",
    "- steps:\n",
    "- load `logfile_df` from the logfile\n",
    "    - NB `logfile_df` has a row for each timestamps\n",
    "    - extract TR information and remove rows corresponding to timestamps before first TR\n",
    "- from `logfile_df`, extract `state_dict`: what events was visited on each wedding\n",
    "- from `logfile_df` and `state_dict`, make `timing_df` \n",
    "    - NB `timing_df` has a row for each event in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import brainiak\n",
    "import nilearn as nl\n",
    "from nilearn import image, plotting, input_data\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "load logfile_df and include calculate the TR of each timestep\n",
    "\"\"\"\n",
    "\n",
    "def read_logfile(sub_num,task='viewing'):\n",
    "  \"\"\" \n",
    "  read psychopy logifle into dataframe\n",
    "  \"\"\"\n",
    "  # initialize dataframe\n",
    "  df = pd.DataFrame(columns=['tstamp','logdata'])\n",
    "  df = df.astype({'tstamp':float})\n",
    "  # open logfile\n",
    "  fpath = 'data/behav/silvy_buckets/sub%iday2/%i_%s.log'%(100+sub_num,sub_num,task)\n",
    "  f = open(fpath, \"r\")\n",
    "  # loop over logfile rows\n",
    "  for x in f:\n",
    "    # deal with S11,39\n",
    "    if len(x.split('\\t')) != 3: continue\n",
    "    tstamp,B,C = x.split('\\t')\n",
    "    tstamp = float(tstamp)\n",
    "    df.loc[tstamp,'logdata'] = C[:-1]\n",
    "    df.loc[tstamp,'tstamp'] = tstamp\n",
    "  return df\n",
    "\n",
    "def include_TR(df):\n",
    "  \"\"\"\n",
    "  takes logdf (indexed by tstamps)\n",
    "  includes the TR on each row\n",
    "  \"\"\"\n",
    "  TR_rate = 1.5\n",
    "  # first TR\n",
    "  first_TR_tstamp = df[df.logdata=='Keypress: equal'].iloc[0].tstamp\n",
    "  # center tstamps on first TR\n",
    "  df.tstamp = df.tstamp-first_TR_tstamp\n",
    "  # include TR column\n",
    "  df['TR'] = np.ceil(df.tstamp/TR_rate)\n",
    "  df = df.astype({'TR':int})\n",
    "  # remove negative TRs\n",
    "  df = df[df.TR>-1]\n",
    "  #  HRF hemodynamic lag \n",
    "  df.TR = df.TR + 3\n",
    "  # reindex by row number\n",
    "  df.index = np.arange(len(df))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "go from logfile_df to timing_df\n",
    "\"\"\"\n",
    "\n",
    "def log2timingdf(df):\n",
    "  \"\"\" \n",
    "  this fun transforms the logfile_df (each timestamp a row) \n",
    "  into the timing_df (each experiment event a row)\n",
    "  edit needed: \n",
    "    fun takes dict with info about the state_value\n",
    "  \"\"\"\n",
    "  vid_strL = ['vid1a','vid1b','vid2','vid3','vid4','vid5',\n",
    "           'vid1a_q','vid1b_q','vid2_q','vid3_q','vid4_q','vid5_q']\n",
    "  df_row_L = []\n",
    "  ## loop over video strings, extract onset TRs\n",
    "  for vid_str in vid_strL:\n",
    "    ## extract onset TR for wedding string\n",
    "    TR_vals = df[df.logdata == '%s: autoDraw = True'%vid_str].TR.values\n",
    "    if vid_str[-2:]=='_q':\n",
    "      df_row = pd.DataFrame.from_dict({\n",
    "        'sub_num':np.repeat(sub_num,2),\n",
    "        'vid_str':np.repeat(vid_str,2),\n",
    "        'wed_num':[0,11],\n",
    "        'onset_TR':TR_vals\n",
    "      })\n",
    "    else:\n",
    "      df_row = pd.DataFrame.from_dict({\n",
    "        'sub_num':np.repeat(sub_num,10),\n",
    "        'vid_str':np.repeat(vid_str,10),\n",
    "        'wed_num':np.arange(1,11),\n",
    "        'onset_TR':TR_vals\n",
    "      })\n",
    "    df_row_L.append(df_row)\n",
    "  df = pd.concat(df_row_L)\n",
    "  df.index = np.arange(len(df))\n",
    "  return df\n",
    "\n",
    "def include_offset_TRs(df):\n",
    "  \"\"\"\n",
    "  includes the offset TRs for each experimental event in a timing df\n",
    "  note from Silvy:\n",
    "    the first 26 seconds are intro, followed by 9 seconds start-event, \n",
    "    17 seconds campfire or flower (depending on label in pkl), \n",
    "    23 seconds coin or torch, 24 seconds egg or painting, and remainder gifts. \n",
    "    NB CURRENTLY USING 10S AS PLACEHOLDER FOR FINAL EVENT (gifts) \n",
    "  \"\"\"\n",
    "\n",
    "  ## dict with len of each vid\n",
    "  TR_rate = 1.5\n",
    "  vid_len_D = {'vid1a':26/TR_rate,'vid1b':9/TR_rate,'vid2':17/TR_rate,\n",
    "               'vid3':23/TR_rate,'vid4':24/TR_rate,'vid5':10/TR_rate,\n",
    "               'vid1a_q':26/TR_rate,'vid1b_q':9/TR_rate,'vid2_q':17/TR_rate,\n",
    "               'vid3_q':23/TR_rate,'vid4_q':24/TR_rate,'vid5_q':10/TR_rate\n",
    "              }\n",
    "  vid_len_D = {k:np.round(v).astype(int) for k,v in vid_len_D.items()}\n",
    "  for vid_str,num_TRs in vid_len_D.items():\n",
    "    df.loc[df['vid_str']==vid_str,'len_TRs'] = int(num_TRs)\n",
    "  df['offset_TR'] = df['onset_TR'] + df['len_TRs']\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_state_dict(logdf):\n",
    "  \"\"\" \n",
    "  returns a dict indexed by (wed_num,state_type)\n",
    "  which gives the state_value [2a,2b,3a,3b,4a,4b]\n",
    "  \"\"\"\n",
    "  init_wed_idx_L = logdf[logdf.logdata.str[:len('Created vid1a_q')] == 'Created vid1a_q'].index\n",
    "  # from these rows, uncover what states were used for given wedding \n",
    "  state_dict = {}\n",
    "  for wed_num,init_wed_idx in enumerate(init_wed_idx_L):\n",
    "    for i,r in logdf.iloc[init_wed_idx:init_wed_idx+6].iterrows():\n",
    "      state_id = r.logdata.split(',')[5].split('/')[1].split('.')[1]\n",
    "      state_dict[(wed_num,int(state_id[0]))] = state_id\n",
    "  return state_dict\n",
    "\n",
    "def include_state_value(df,state_dict):\n",
    "  \"\"\" \n",
    "  uses state_dict to include the column state_value in timing_df\n",
    "  \"\"\"\n",
    "  df.loc[:,'state'] = 'N/A'\n",
    "  for i,r in df.iterrows():\n",
    "    state_value = state_dict[(r.wed_num,int(r.vid_str[3]))]\n",
    "    df.loc[i,'state'] = state_value\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub_timing_df(sub_num):\n",
    "  \"\"\" \n",
    "  main wrapper function for loading info of a given subject\n",
    "  \"\"\"\n",
    "  logdf = read_logfile(sub_num,task='viewing')\n",
    "  logdf = include_TR(logdf)\n",
    "  state_dict = get_state_dict(logdf)\n",
    "  ## from logfile_df to timing_df\n",
    "  df = log2timingdf(logdf)\n",
    "  df = include_state_value(df,state_dict)\n",
    "  df = include_offset_TRs(df)\n",
    "  df = df.astype({'onset_TR':int,'len_TRs':int,'offset_TR':int})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "err 0\n",
      "1\n",
      "err 1\n",
      "2\n",
      "err 2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "err 16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "err 20\n",
      "21\n",
      "err 21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "loop over subjects\n",
    "\"\"\"\n",
    "sub_df_L = []\n",
    "for sub_num in np.arange(45):\n",
    "  print(sub_num)\n",
    "  try:\n",
    "    sub_timing_df = load_sub_timing_df(sub_num)\n",
    "    sub_df_L.append(sub_timing_df)\n",
    "  except:\n",
    "    print('err',sub_num)\n",
    "timing_df = pd.concat(sub_df_L)\n",
    "\n",
    "# unique index per row\n",
    "timing_df.index = np.arange(len(timing_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# include wedding id and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-986388d66e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtiming_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiming_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'wed_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5520\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5521\u001b[0m                     results.append(\n\u001b[0;32m-> 5522\u001b[0;31m                         \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5523\u001b[0m                     )\n\u001b[1;32m   5524\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5535\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5536\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5537\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5538\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     def convert(\n",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/brain/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "wed_df = pd.read_csv('deriv/NvSclass_df.csv',index_col=0)\n",
    "for idx,row in timing_df.iterrows():\n",
    "  wed_row = wed_df[(wed_df.wed_num == row.wed_num) & (wed_df.sub_num == row.sub_num)]\n",
    "  if len(wed_row):\n",
    "    timing_df.loc[idx,'schema'] = wed_row.NorS.values[0]\n",
    "    timing_df.loc[idx,'wed_id'] = wed_row.wed_id.values[0]\n",
    "  else:\n",
    "    print(row.sub_num)\n",
    "    \n",
    "timing_df = timing_df.astype({'wed_id':int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleanup and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df = timing_df.sort_values('onset_TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df.to_csv('deriv/view_df.csv')\n",
    "timing_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
